<FrameworkSwitchCourse {fw} />

<div dir="rtl">
# به کارگیری مدل‌های از پیش تعلیم دیده

{#if fw === 'pt'}

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter4/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter4/section2_pt.ipynb"},
]} />

{:else}

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter4/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter4/section2_tf.ipynb"},
]} />

{/if}

هاب مدل، انتخاب مدل مناسب را تسهیل می‌بخشد؛ به طوری که می‌توان با چند خط کد، آن را در هر کتابخانه پایین‌دستی وابسته استفاده نمود. بیایید به نحوه عملی به کارگیری یکی از این مدل‌ها نگاهی انداخته و ببینیم چگونه می‌توانیم در مقام کمک به جامعه کاربران برآییم.

فرض کنید به دنبال مدلی مبتنی بر زبان فرانسوی هستیم که قادر به پر کردن جاهای خالی متن است.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/camembert.gif" alt="انتخاب مدل Camembert" width="80%"/>
</div>

نقطه تعلیم `camembert-base` را انتخاب می‌کنیم تا مدل را با آن آزمایش نماییم. برای شروع استفاده از آن، تمام آنچه نیاز داریم شناسه `camembert-base`  است! همان گونه که در فصل‌های پیشین دیدید، می‌توانیم با استفاده از تابع `pipeline()` نمونه شیءای از آن بسازیم.

<div dir="ltr">

```py
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
```

```python out
[
  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49091005325317383, 'token': 7200, 'token_str': 'délicieux'}, 
  {'sequence': 'Le camembert est excellent :)', 'score': 0.1055697426199913, 'token': 2183, 'token_str': 'excellent'}, 
  {'sequence': 'Le camembert est succulent :)', 'score': 0.03453313186764717, 'token': 26202, 'token_str': 'succulent'}, 
  {'sequence': 'Le camembert est meilleur :)', 'score': 0.0330314114689827, 'token': 528, 'token_str': 'meilleur'}, 
  {'sequence': 'Le camembert est parfait :)', 'score': 0.03007650189101696, 'token': 1654, 'token_str': 'parfait'}
]
```

</div>

همان طور که می‌بینید، بارگذاری مدل درون خط تولید بسیار ساده است. تنها چیزی که باید مراقبش باشید این است که نقطه تعلیم انتخاب شده، مناسب وظیفه‌ای باشد که برای انجام آن به کار گرفته خواهد شد. برای مثال، در اینجا نقطه تعلیم `camembert-base` را در خط تولید `fill-mask` استفاده می‌کنیم، که انتخابی کاملا معقول است. اما اگر ما این نقطه تعلیم را در خط تولید `text-classification` استفاده کنیم، نتایج هیچ معنایی نخواهند داشت، زیرا سَر مربوط به `camembert-base`، برای این کار مناسب نیست. توصیه می‌کنیم که از انتخاب‌گر وظیفه در رابط کاربری هاب هاگینگ‌فِیس برای انتخاب نقاط تعلیم مناسب استفاده نمایید:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/tasks.png" alt="انتخاب‌گر وظیفه در رابط کاربری تحت وب" width="80%"/>
</div>

همچنین می‌توانید نمونه‌سازی از نقطه تعلیم را مستقیما با استفاده از معماری مدل انجام دهید:

{#if fw === 'pt'}

<div dir="ltr">

```py
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
```

</div>

با این حال، توصیه می‌کنیم به جای این کار از [`Auto*` classes](https://huggingface.co/transformers/model_doc/auto.html?highlight=auto#auto-classes) استفاده کنید؛ چرا که طراحی این کلاس‌های خودکار به گونه‌ایست که فارغ از هرگونه وابستگی به معماری به کار رفته هستند. در حالی که نمونه کد قبلی، کاربران را محدود به نقاط تعلیم قابل بارگذاری در معماری CamemBERT می‌کند، استفاده از کلاس‌های `Auto*`، سهولت تعویض نقاط تعلیم را در بر دارد:

<div dir="ltr">

```py
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
```

</div>

{:else}

<div dir="ltr">

```py
from transformers import CamembertTokenizer, TFCamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = TFCamembertForMaskedLM.from_pretrained("camembert-base")
```

</div>

با این حال، توصیه می‌کنیم به جای این کار از [`TFAuto*` classes](https://huggingface.co/transformers/model_doc/auto.html?highlight=auto#auto-classes) استفاده کنید؛ چرا که طراحی این کلاس‌های خودکار به گونه‌ایست که، فارغ از هرگونه وابستگی به معماری به کار رفته هستند. در حالی که نمونه کد قبلی، کاربران را محدود به نقاط تعلیم قابل بارگذاری در معماری CamemBERT می‌کند، استفاده از کلاس‌های `TFAuto*`، سهولت تعویض نقاط تعلیم را در بر دارد:

<div dir="ltr">

```py
from transformers import AutoTokenizer, TFAutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = TFAutoModelForMaskedLM.from_pretrained("camembert-base")
```

</div>

{/if}

<Tip>
هنگامی که مدلی از پیش تعلیم دیده را استفاده می‌کنید، حتما بررسی کنید که این تعلیم چگونه و روی چه دیتاسِت‌هایی صورت پذیرفته و چه محدودیت‌ها و سوگیری‌هایی را شامل می‌شود. تمامی این اطلاعات می‌بایست در صفحه توضیحات مدل نشان داده شوند.
</Tip>

</div>
